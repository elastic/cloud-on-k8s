[id="{p}-quickstart"]
== Quickstart

With Elastic Cloud on Kubernetes (ECK) you can extend the basic Kubernetes orchestration capabilities to easily deploy, secure, upgrade your Elasticsearch cluster, and much more.

Eager to get started? This fast guide shows you how to:

* <<{p}-deploy-eck,Deploy ECK in your Kubernetes cluster>>
* <<{p}-deploy-elasticsearch,Deploy the Elasticsearch cluster>>
* <<{p}-deploy-kibana,Deploy the Kibana instance>>
* <<{p}-upgrade-deployment,Upgrade your deployment>>
* <<{p}-persistent-storage,Use persistent storage>>
* <<{p}-check-samples,Check out the samples>>

**Requirements**

Make sure that you have link:https://kubernetes.io/docs/tasks/tools/install-kubectl/[kubectl] version 1.11+ installed.

[float]
[id="{p}-deploy-eck"]
=== Deploy ECK in your Kubernetes cluster

NOTE: If you are using GKE, make sure your user has `cluster-admin` permissions. For more information, see link:https://cloud.google.com/kubernetes-engine/docs/how-to/role-based-access-control#iam-rolebinding-bootstrap[Prerequisites for using Kubernetes RBAC on GKE].

NOTE: If you are using Amazon EKS, make sure the Kubernetes control plane is allowed to communicate with nodes port 443. This is required for communication with the Validating Webhook. For more information, see link:https://docs.aws.amazon.com/eks/latest/userguide/sec-group-reqs.html[Recommended inbound traffic].

. Install link:https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/[custom resource definitions] and the operator with its RBAC rules:
+
[source,sh]
----
kubectl apply -f https://download.elastic.co/downloads/eck/0.8.0/all-in-one.yaml
----

. Monitor the operator logs:
+
[source,sh]
----
kubectl -n elastic-system logs -f statefulset.apps/elastic-operator
----

[float]
[id="{p}-deploy-elasticsearch"]
=== Deploy the Elasticsearch cluster

Apply a simple link:{ref}/getting-started.html[Elasticsearch] cluster specification, with one node:

NOTE: The default resource request is 2gb memory and 100m cpu, and your pod will be `Pending` if your cluster does not have enough resources.

[source,yaml]
----
cat <<EOF | kubectl apply -f -
apiVersion: elasticsearch.k8s.elastic.co/v1alpha1
kind: Elasticsearch
metadata:
  name: quickstart
spec:
  version: 7.2.0
  nodes:
  - nodeCount: 1
    config:
      node.master: true
      node.data: true
      node.ingest: true
EOF
----

The operator automatically manages Pods and resources corresponding to the desired cluster. It may take up to a few minutes until the cluster is ready.

[float]
==== Monitor cluster health and creation progress

Get an overview of the current Elasticsearch clusters in the Kubernetes cluster, including health, version and number of nodes:

[source,sh]
----
kubectl get elasticsearch
----

[source,sh]
----
NAME          HEALTH    NODES     VERSION   PHASE         AGE
quickstart    green     1         7.2.0     Operational   1m
----

When you create the cluster, there is no `HEALTH` status and the `PHASE` is `Pending`. After a while, the `PHASE` turns into `Operational`, and `HEALTH` becomes `green`.

You can see that one Pod is in the process of being started:

[source,sh]
----
kubectl get pods --selector='elasticsearch.k8s.elastic.co/cluster-name=quickstart'
----

[source,sh]
----
NAME                       READY     STATUS    RESTARTS   AGE
quickstart-es-5zctxpn8nd   1/1       Running   0          1m
----

Access the logs for that Pod:

[source,sh]
----
kubectl logs -f quickstart-es-5zctxpn8nd
----

[float]
==== Request Elasticsearch access

A ClusterIP Service is automatically created for your cluster:

[source,sh]
----
kubectl get service quickstart-es-http
----

[source,sh]
----
NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
quickstart-es-http   ClusterIP   10.15.251.145   <none>        9200/TCP   34m
----

. Get the credentials.
+
A default user named `elastic` is automatically created. Its password is stored as a Kubernetes secret:
+
[source,sh]
----
PASSWORD=$(kubectl get secret quickstart-es-elastic-user -o=jsonpath='{.data.elastic}' | base64 --decode)
----

. Request the Elasticsearch endpoint.
+
From inside the Kubernetes cluster:
+
[source,sh]
----
curl -u "elastic:$PASSWORD" -k "https://quickstart-es-http:9200"
----
+
From your local workstation, use the following command in a separate terminal:
+
[source,sh]
----
kubectl port-forward service/quickstart-es-http 9200
----
+
Then request `localhost`:
+
[source,sh]
----
curl -u "elastic:$PASSWORD" -k "https://localhost:9200"
----

NOTE: For testing purposes only, you can specify the `-k` option to turn off certificate verification.

[source,json]
----
{
  "name" : "quickstart-es-r56c9dzzcr",
  "cluster_name" : "quickstart",
  "cluster_uuid" : "XqWg0xIiRmmEBg4NMhnYPg",
  "version" : {
    "number" : "7.2.0",
    "build_flavor" : "default",
    "build_type" : "docker",
    "build_hash" : "04116c9",
    "build_date" : "2019-05-08T06:20:03.781729Z",
    "build_snapshot" : true,
    "lucene_version" : "8.0.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}
----

[float]
[id="{p}-deploy-kibana"]
=== Deploy the Kibana instance

To deploy your link:{kibana-ref}/introduction.html#introduction[Kibana] instance go through the following steps.

. Specify a Kibana instance and associate it with your Elasticsearch cluster:
+
[source,yaml]
----
cat <<EOF | kubectl apply -f -
apiVersion: kibana.k8s.elastic.co/v1alpha1
kind: Kibana
metadata:
  name: quickstart
spec:
  version: 7.2.0
  nodeCount: 1
  elasticsearchRef:
    name: quickstart
EOF
----

. Monitor Kibana health and creation progress.
+
Similarly to Elasticsearch, you can retrieve details about Kibana instances:
+
[source,sh]
----
kubectl get kibana
----
+
And the associated Pods:
+
[source,sh]
----
kubectl get pod --selector='kibana.k8s.elastic.co/name=quickstart'
----

. Access Kibana.
+
A `ClusterIP` Service is automatically created for Kibana:
+
[source,sh]
----
kubectl get service quickstart-kb-http
----
+
Use `kubectl port-forward` to access Kibana from your local workstation:
+
[source,sh]
----
kubectl port-forward service/quickstart-kb-http 5601
----
+
Open `http://localhost:5601` in your browser.
+
Login with the `elastic` user. Retrieve its password with:
+
[source,sh]
----
echo $(kubectl get secret quickstart-es-elastic-user -o=jsonpath='{.data.elastic}' | base64 --decode)
----

[float]
[id="{p}-upgrade-deployment"]
=== Upgrade your deployment

You can apply any modification to the original cluster specification. The operator makes sure that your changes are applied to the existing cluster, while avoiding downtime.

For example, you can grow the cluster to three nodes:

[source,yaml]
----
cat <<EOF | kubectl apply -f -
apiVersion: elasticsearch.k8s.elastic.co/v1alpha1
kind: Elasticsearch
metadata:
  name: quickstart
spec:
  version: 7.2.0
  nodes:
  - nodeCount: 3
    config:
      node.master: true
      node.data: true
      node.ingest: true
EOF
----

[float]
[id="{p}-persistent-storage"]
=== Use persistent storage

Now that you have completed the quickstart, you can try out more features like using persistent storage. The cluster that you deployed in this quickstart uses a default persistent volume claim of 1GiB, without a storage class set. This means that the default storage class defined in the Kubernetes cluster is the one that will be provisioned.

You can request a `PersistentVolumeClaim` in the cluster specification, to target any `PersistentVolume` class available in your Kubernetes cluster:

[source,yaml]
----
cat <<EOF | kubectl apply -f -
apiVersion: elasticsearch.k8s.elastic.co/v1alpha1
kind: Elasticsearch
metadata:
  name: quickstart
spec:
  version: 7.2.0
  nodes:
  - nodeCount: 3
    config:
      node.master: true
      node.data: true
      node.ingest: true
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 10Gi
        #storageClassName: standard # can be any available storage class
EOF
----

To aim for the best performance, the operator supports persistent volumes local to each node. For more details, see:

 * link:https://kubernetes.io/docs/concepts/storage/storage-classes[persistent volumes storage classes]
 * link:https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner[kubernetes-sigs local volume static provisioner] to setup static local volumes.

[float]
[id="{p}-check-samples"]
=== Check out the samples

You can find a set of sample resources link:https://github.com/elastic/cloud-on-k8s/tree/master/operators/config/samples[in the project repository].
To customize the Elasticsearch resource, check the link:https://github.com/elastic/cloud-on-k8s/blob/master/operators/config/samples/elasticsearch/elasticsearch.yaml[Elasticsearch sample].

For a full description of each `CustomResourceDefinition`, go to link:https://github.com/elastic/cloud-on-k8s/tree/master/operators/config/crds[the project repository].
You can also retrieve it from the cluster. For example, describe the Elasticsearch CRD specification with:

[source,sh]
----
kubectl describe crd elasticsearch
----
