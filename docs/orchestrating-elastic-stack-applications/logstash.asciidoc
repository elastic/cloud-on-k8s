:page_id: logstash
:logstash_recipes: https://raw.githubusercontent.com/elastic/cloud-on-k8s/{eck_release_branch}/config/recipes/logstash
ifdef::env-github[]
****
link:https://www.elastic.co/guide/en/cloud-on-k8s/master/k8s-{page_id}.html[View this document on the Elastic website]
****
endif::[]
[id="{p}-{page_id}"]
= Run Logstash on ECK

experimental[]

This section describes how to configure and deploy Logstash with ECK.

* <<{p}-logstash-quickstart,Quickstart>>
* <<{p}-logstash-configuration,Configuration>>
* <<{p}-logstash-configuration-examples,Configuration examples>>
* <<{p}-logstash-technical-preview-limitations,Technical Preview Limitations>>


NOTE: Running Logstash on ECK is compatible only with Logstash 8.7+.


[id="{p}-logstash-quickstart"]
== Quickstart


. Apply the following specification to deploy Elastic Agent with the System metrics integration to harvest CPU metrics from the Agent Pods. ECK automatically configures the secured connection to an Elasticsearch cluster named `quickstart`, created in the link:k8s-quickstart.html[Elasticsearch quickstart].
+
[source,yaml,subs="attributes,+macros,callouts"]
----
cat $$<<$$EOF | kubectl apply -f -
apiVersion: logstash.k8s.elastic.co/v1alpha1
kind: Logstash
metadata:
  name: quickstart
spec:
  count: 3
  version: 8.6.1
  config:
  elasticsearchRefs:
    - clusterName: quickstart
      name: quickstart
  pipelines:
    - pipeline.id: main
      config.string: |
        input {
          beats {
            port => 5044
          }
        }
        output {
          elasticsearch {
            hosts => [ "${QUICKSTART_ES_HOSTS}" ]
            user => "${QUICKSTART_ES_USER}"
            password => "${QUICKSTART_ES_PASSWORD}"
            cacert => "${QUICKSTART_ES_CA_CERTS}"
          }
        }
  services:
    - name: beats
      service:
        spec:
          type: ClusterIP
          ports:
            - port: 5044
              name: "filebeat"
              protocol: TCP
              targetPort: 5044
EOF
----
+
Check <<{p}-logstash-configuration-examples>> for more ready-to-use manifests.

. Monitor the status of Logstash
+
[source,sh]
----
kubectl get logstash
----
+
[source,sh,subs="attributes"]
----
NAME              AVAILABLE   EXPECTED   AGE   VERSION
quickstart        3           3          4s    {version}
----

. List all the Pods that belong to a given Logstash specification.
+
[source,sh]
----
kubectl get pods --selector='logstash.k8s.elastic.co/name=quickstart'
----
+
[source,sh]
----
NAME              READY   STATUS    RESTARTS   AGE
quickstart-ls-0   1/1     Running   0          91s
quickstart-ls-1   1/1     Running   0          91s
quickstart-ls-2   1/1     Running   0          91s
----

. Access logs for one of the Pods.
+
[source,sh]
----
kubectl logs -f quickstart-ls-0
----

== Configuration

[id="{p}-logstash-upgrade-specification"]
=== Upgrade the Logstash specification

You can upgrade the Logstash version or change settings by editing the YAML specification. ECK applies the changes by performing a rolling restart of Logstash's Pods.

[id="{p}-logstash-custom-configuration"]
=== Customize the Logstash configuration

The Logstash configuration (equivalent to logstash.yml) is defined in the `config` element:

[source,yaml,subs="attributes,+macros,callouts"]
----
apiVersion: logstash.k8s.elastic.co/v1alpha1
kind: Logstash
metadata:
  name: quickstart
spec:
  version: {version}
  elasticsearchRefs:
  - name: quickstart
  config:
----

Alternatively, it can be provided through a Secret specified in the `configRef` element. The Secret must have an `logstash.yml` entry with this configuration:
[source,yaml,subs="attributes,+macros"]
----
apiVersion: logstash.k8s.elastic.co/v1alpha1
kind: Logstash
metadata:
  name: quickstart
spec:
  version: {version}
  elasticsearchRefs:
  - name: quickstart
  configRef:
    secretName: quickstart-config
---
apiVersion: v1
kind: Secret
metadata:
  name: quickstart-config
stringData:
  logstash.yml: |-
----


[id="{p}-logstash-pipelines"]
=== Adding Logstash Pipelines

Logstash pipelines (equivalent to pipelines.yml) are defined in the `pipelines` element:

[source,yaml,subs="attributes,+macros,callouts"]
----
apiVersion: logstash.k8s.elastic.co/v1alpha1
kind: Logstash
metadata:
  name: quickstart
spec:
  version: {version}
  elasticsearchRefs:
  - name: quickstart
  pipelines:
    - pipeline.id: main
      config.string: |
        input {
          beats {
            port => 5044
          }
        }
        output {
          elasticsearch {
            hosts => [ "${QUICKSTART_ES_HOSTS}" ]
            user => "${QUICKSTART_ES_USER}"
            password => "${QUICKSTART_ES_PASSWORD}"
            cacert => "${QUICKSTART_ES_CA_CERTS}"
          }
        }
----

Alternatively, it can be provided through a Secret specified in the `configRef` element. The Secret must have an `logstash.yml` entry with this configuration:
[source,yaml,subs="attributes,+macros"]
----
apiVersion: logstash.k8s.elastic.co/v1alpha1
kind: Logstash
metadata:
  name: quickstart
spec:
  version: {version}
  elasticsearchRefs:
  - name: quickstart
  pipelinesRef:
    secretName: quickstart-pipeline
---
apiVersion: v1
kind: Secret
metadata:
  name: quickstart-pipeline
stringData:
  pipelines.yml: |-
    - pipeline.id: main
      config.string: |
        input {
          beats {
            port => 5044
          }
        }
        output {
          elasticsearch {
            hosts => [ "${QUICKSTART_ES_HOSTS}" ]
            user => "${QUICKSTART_ES_USER}"
            password => "${QUICKSTART_ES_PASSWORD}"
            cacert => "${QUICKSTART_ES_CA_CERTS}"
          }
        }

----

Logstash on ECK supports all options in `pipelines.yml`, including settings to update the number of workers, and
 the size of the batch that the pipeline will process. This also includes using `path.config` to point to volumes
 mounted on the logstash container:

[source,yaml,subs="attributes,+macros"]
----
apiVersion: logstash.k8s.elastic.co/v1alpha1
kind: Logstash
metadata:
  name: quickstart
spec:
  version: {version}
  count: 1
  pipelines:
    - pipeline.id: external
      pipeline.workers: 4
      path.config: /usr/share/logstash/config/pipelines
  podTemplate:
    spec:
      containers:
        - name: logstash
          volumeMounts:
          - mountPath: /usr/share/logstash/config/pipelines
            name: pipelines
            readOnly: true
      volumes:
      - name: pipelines
        hostPath:
          path: /home/logstash-dev/logstash/pipelines
----

NOTE: Persistent Queues and Dead Letter Queues will be supported in a later release, but are not currently suppored.

[source,yaml,subs="attributes,+macros"]
----
apiVersion: logstash.k8s.elastic.co/v1alpha1
kind: Logstash
metadata:
  name: quickstart
spec:
  version: {version}
  elasticsearchRefs:
  - name: quickstart
    outputName: default
  - name: agent-monitoring
    namespace: elastic-monitoring
    outputName: monitoring
...
----

[id="{p}-logstash-connect-es"]
=== Customize the connection to an Elasticsearch cluster

The `elasticsearchRefs` element allows ECK to automatically configure Elastic Agent to establish a secured connection to one or more managed Elasticsearch clusters. By default, it targets all nodes in your cluster. If you want to direct traffic to specific nodes of your Elasticsearch cluster, refer to <<{p}-traffic-splitting>> for more information and examples.

Check <<{p}-compute-resources-beats-agent>> for more information on how to use the Pod template to adjust the resources given to Elastic Agent.


[id="{p}-logstash-configuration-examples"]
== Configuration examples

This section contains manifests that illustrate common use cases, and can be your starting point in exploring Logstash deployed with ECK. These manifests are self-contained and work out-of-the-box on any non-secured Kubernetes cluster. They all contain a three-node Elasticsearch cluster and a single Kibana instance.

CAUTION: The examples in this section are for illustration purposes only and should not be considered to be production-ready. Some of these examples use the `node.store.allow_mmap: false` setting which has performance implications and should be tuned for production workloads, as described in <<{p}-virtual-memory>>.


=== Single Pipeline

[source,sh,subs="attributes"]
----
kubectl apply -f {logstash_recipes}/single-pipeline.yaml
----

Deploys Logstash with a single pipeline

=== Multiple Pipelines

[source,sh,subs="attributes"]
----
kubectl apply -f {logstash_recipes}/multiple-pipelines.yaml
----

Deploys Logstash with multiple pipelines

=== Elasticsearch and Kibana Stack Monitoring

[source,sh,subs="attributes"]
----
kubectl apply -f {logstash_recipes}/stack_monitoring.yaml
----

Deploys Metricbeat configured for Elasticsearch and Kibana link:https://www.elastic.co/guide/en/kibana/current/xpack-monitoring.html[Stack Monitoring] and Filebeat using autodiscover. Deploys one monitored Elasticsearch cluster and one monitoring Elasticsearch cluster. You can access the Stack Monitoring app in the monitoring cluster's Kibana.

NOTE: In this example, TLS verification is disabled when Metricbeat communicates with the monitored cluster, which is not secure and should not be used in production. To solve this, use custom certificates and configure Metricbeat to verify them.

[id="{p}-logstash-on-eck-limitations"]
== Logstash on ECK Limitations

* When running Logstash on ECK, it is important to understand how data is sent into Logstash when determining replica counts of pods. Pipelines that include plugins that need to store state, or cannot automatically distribute work across pods should be treated with care as data loss and/or duplication can result from incorrectly configured setups
* To that end, the technical preview should only be run with a limited set of input plugins:

[id="{p}-logstash-technical-preview-limitations"]
== Technical Preview Limitations

Note that this release is a technical preview, is still under active development and has limited functionality.
Limitations include, but are not limited to:

* Limited support for plugins -
** Input plugins: logstash-input-azure_event_hubs, logstash-input-beats, logstash-input-elastic_agent, logstash-input-kafka, logstash-input-tcp, logstash-input-http
** While most filter plugins are supported, the following plugins are not currently supported:
*** logstash-filter-jdbc_static, logstash-filter-jdbc_streaming, logstash-filter-aggregate
*** Other filters may require additional manual work to mount volumes
** While most output plugins are supported, the following plugins are not currently supported, or may require manual work to be operational:
*** logstash-output-s3 - requires a volume mount to store in progress work to avoid data loss
*** logstash-output-jms - requires jar files to be placed on the logstash classpath


* No support for persistence
* `ElasticsearchRef` implementation in plugins in preview mode
** In preview mode, plugins will need to be populated with environment variables populated by the Logstash operator.
* No `ElasticsearchRef` support for Pipeline Central Management
** Manual configuration required in `Config`/`ConfigRef`
