:parent_page_id: elasticsearch-specification
:page_id: snapshots
ifdef::env-github[]
****
link:https://www.elastic.co/guide/en/cloud-on-k8s/master/k8s-{parent_page_id}.html#k8s-{page_id}[View this document on the Elastic website]
****
endif::[]
[id="{p}-{page_id}"]
= Create automated snapshots

To set up automated snapshots for Elasticsearch on Kubernetes you have to:

. Register the snapshot repository with the Elasticsearch API.
. Set up a Snapshot Lifecycle Management Policy via https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshot-lifecycle-management-api.html[API] or the https://www.elastic.co/guide/en/kibana/current/snapshot-repositories.html[Kibana UI]


NOTE: Support for S3, GCS and Azure repositories is bundled in Elasticsearch by default from version 8.0. On older versions of Elasticsearch or if another snapshot repository plugin should be used you have to <<{p}-install-plugin>>

For more information on Elasticsearch snapshots, check https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshot-restore.html[Snapshot and Restore] in the Elasticsearch documentation.

What follows is a non-exhaustive list of configuration examples. The first example might be worth reading even if you are targeting a Cloud provider other than GCP as it covers adding snapshot repository credentials to the Elasticsearch keystore and illustrates the basic workflow of setting up a snapshot repository:

* <<{p}-basic-snapshot-gcs>>

The next two examples cover approaches that use Cloud-provider specific means to leverage Kubernetes service accounts to avoid having to configure snapshot repository credentials in Elasticsearch:

* <<{p}-gke-workload-identiy>>
* <<{p}-iam-service-accounts>>


== Configuration examples

[id="{p}-basic-snapshot-gcs"]
=== Basic snapshot repository setup using GCS as an example

[id="{p}-secure-settings"]
==== Configure GCS credentials through the Elasticsearch keystore

The Elasticsearch GCS repository plugin requires a JSON file that contains service account credentials. These need to be added as secure settings to the Elasticsearch keystore. For more details, check https://www.elastic.co/guide/en/elasticsearch/reference/current/repository-gcs.html[Google Cloud Storage Repository].

Using ECK, you can automatically inject secure settings into a cluster node by providing them through a secret in the Elasticsearch Spec.

. Create a file containing the GCS credentials. For this example, name it `gcs.client.default.credentials_file`. The file name is important as it is reflected in the secure setting.
+
[source,json]
----
{
  "type": "service_account",
  "project_id": "your-project-id",
  "private_key_id": "...",
  "private_key": "-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n",
  "client_email": "service-account-for-your-repository@your-project-id.iam.gserviceaccount.com",
  "client_id": "...",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://accounts.google.com/o/oauth2/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/your-bucket@your-project-id.iam.gserviceaccount.com"
}
----

. Create a Kubernetes secret from that file:
+
[source,sh]
----
kubectl create secret generic gcs-credentials --from-file=gcs.client.default.credentials_file
----

. Edit the `secureSettings` section of the Elasticsearch resource:
+
[source,yaml,subs="attributes"]
----
apiVersion: elasticsearch.k8s.elastic.co/{eck_crd_version}
kind: Elasticsearch
metadata:
  name: elasticsearch-sample
spec:
  version: {version}
  # Inject secure settings into Elasticsearch nodes from a k8s secret reference
  secureSettings:
  - secretName: gcs-credentials
----
If you haven't followed these instructions and named your GCS credentials file differently, you can still map it to the expected name now. Check <<{p}-es-secure-settings,Secure Settings>> for details.
. Apply the modifications:
+
[source,bash]
----
kubectl apply -f elasticsearch.yml
----

GCS credentials are automatically propagated into each Elasticsearch node's keystore. It can take up to a few minutes, depending on the number of secrets in the keystore. You don't have to restart the nodes.

[id="{p}-create-repository"]
==== Register the repository in Elasticsearch

. Create the GCS snapshot repository in Elasticsearch. You can either use the https://www.elastic.co/guide/en/kibana/current/snapshot-repositories.html[Snapshot and Restore UI] in Kibana version 7.4.0 or higher, or follow the procedure described in https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html[Snapshot and Restore]:

+
[source,sh]
----
PUT /_snapshot/my_gcs_repository
{
  "type": "gcs",
  "settings": {
    "bucket": "my_bucket",
    "client": "default"
  }
}
----

. Take a snapshot with the following HTTP request:
+
[source,sh]
----
PUT /_snapshot/my_gcs_repository/test-snapshot
----

[id="{p}-gke-workload-identiy"]
=== Use GKE Workload Identity
GKE Workload Identity allows a Kubernetes service account to impersonate a Google Cloud IAM service account and therefore to configure a snapshot repository in Elasticsearch without storing Google Cloud credentials in Elasticsearch itself. This feature requires your Kubernetes cluster to run on GKE and your Elasticsearch cluster to run at least https://github.com/elastic/elasticsearch/pull/71239[version 7.13] and https://github.com/elastic/elasticsearch/pull/82974[version 8.1] when using searchable snapshots.

Follow the instructions in the https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity[GKE documentation] to configure workload identity, specifically:

. Create or update your Kubernetes cluster with `--workload-pool=PROJECT_ID.svc.id.goog` enabled, where `PROJECT_ID` is your Google project ID
. Create a namespace and a Kubernetes service account (`test-gcs` and `gcs-sa` in this example)
. Create the bucket, the Google service account (`gcp-sa` in this example, note that both Google and Kubernetes have the concept of a service account, this is about the former) and set the relevant permissions through Google Cloud console or gcloud CLI
. Allow the Kubernetes service account to impersonate the Google service:
+
[source,sh]
----
gcloud iam service-accounts add-iam-policy-binding gcp-sa@PROJECT_ID.iam.gserviceaccount.com \
--role roles/iam.workloadIdentityUser \
--member "serviceAccount:PROJECT_ID.svc.id.goog[test-gcs/gcs-sa]"
----
+
.  Add the `iam.gke.io/gcp-service-account` annotation on the Kubernetes service account
+
[source,sh]
----
kubectl annotate serviceaccount gcs-sa \
    --namespace test-gcs \
    iam.gke.io/gcp-service-account=gcp-sa@PROJECT_ID.iam.gserviceaccount.com
----
+
. Create an Elasticsearch cluster, referencing the Kubernetes service account
+
[source,yaml]
----
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: elasticsearch-gcs-sample
  namespace: test-gcs
spec:
  version: {version}
  nodeSets:
  - name: default
    podTemplate:
      spec:
        automountServiceAccountToken: true
        serviceAccountName: gcs-sa
    count: 3
----
+
. Create the snapshot repository as described in <<{p}-create-repository>>

[id="{p}-iam-service-accounts"]
=== Use AWS IAM roles for service accounts (IRSA)

The AWS IAM roles for service accounts feature allows you to give Elasticsearch restricted access to a S3 bucket without having to expose and store AWS credentials directly in Elasticsearch. This requires you to run the ECK operator on Amazon's EKS offering and an https://www.elastic.co/guide/en/elasticsearch/reference/8.1/repository-s3.html#iam-kubernetes-service-accounts[Elasticsearch cluster running at least version 8.1].

Follow https://aws.amazon.com/premiumsupport/knowledge-center/eks-restrict-s3-bucket/[the AWS documentation] to set this feature up, specifically you need to:

. Define an IAM policy file, called `iam-policy.json` in this example
+
[source,json]
----
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": [
                "s3:ListBucketMultipartUploads",
                "s3:ListBucketVersions",
                "s3:ListBucket",
                "s3:GetBucketLocation"
            ],
            "Resource": "arn:aws:s3:::my_bucket"
        },
        {
            "Sid": "VisualEditor1",
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:GetObject",
                "s3:AbortMultipartUpload",
                "s3:DeleteObject",
                "s3:ListMultipartUploadParts"
            ],
            "Resource": "arn:aws:s3:::my_bucket/*"
        }
    ]
}
----
+
. Create the policy using AWS CLI tooling, using the name `eck-snapshots` in this example
+
[source,sh]
----
aws iam create-policy \
    --policy-name eck-snapshots \
    --policy-document file://iam-policy.json
----
+
. Use `eksctl` to create an IAM role and create and annotate a Kubernetes service account with it. The service account is called `aws-sa` in the `default` namespace in this example.
+
[source,sh,subs="attributes,callouts"]
----
eksctl create iamserviceaccount \
  --name aws-sa \
  --namespace default \
  --cluster YOUR_CLUSTER \ <1>
  --attach-policy-arn arn:aws:iam::YOUR_IAM_ARN:policy/eck-snapshots \ <2>
  --approve
----
+
<1> Replace `YOUR_CLUSTER` with your actual EKS cluster name
<2> Replace with the actual AWS IAM ARN for the policy you just created
+
. Create an Elasticsearch cluster referencing the service account
+
[source,yaml,subs="attributes,callouts"]
----
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: es
spec:
  version: {version}
  nodeSets:
  - name: default
    podTemplate:
      spec:
        serviceAccountName: aws-sa
        containers:
        - name: elasticsearch
          env:
          - name: AWS_WEB_IDENTITY_TOKEN_FILE
            value: "/usr/share/elasticsearch/config/repository-s3/aws-web-identity-token-file" <1>
          - name: AWS_ROLE_ARN
            value: "arn:aws:iam::YOUR_ROLE_ARN_HERE" <2>
          volumeMounts:
          - name: aws-iam-token
            mountPath: /usr/share/elasticsearch/config/repository-s3
        volumes:
          - name: aws-iam-token
            projected:
              sources:
              - serviceAccountToken:
                  audience: sts.amazonaws.com
                  expirationSeconds: 86400
                  path: aws-web-identity-token-file
----
+
<1> Elasticsearch expects the service account token to be projected to exactly this path
<2> Replace with the actual `AWS_ROLE_ARN` for the IAM role you created in step 3
+
. Create the snapshot repository as described in <<{p}-create-repository>> but of type `s3`
+
[source,sh]
----
PUT /_snapshot/my_s3_repository
{
  "type": "s3",
  "settings": {
    "bucket": "my_bucket",
  }
}
----



[id="{p}-install-plugin"]
=== Install a snapshot repository plugin

If you are running a version of Elasticsearch before 8.0 or you need a snapshot repository plugin that is not already pre-installed you have to install the plugin yourself. To install the snapshot repository plugin, you can either use a <<{p}-custom-images,custom image>> or <<{p}-init-containers-plugin-downloads,add your own init container>> which
installs the plugin when the Pod is created.

To use your own custom image with all necessary plugins pre-installed, use an Elasticsearch resource like the following one:

[source,yaml,subs="attributes"]
----
apiVersion: elasticsearch.k8s.elastic.co/{eck_crd_version}
kind: Elasticsearch
metadata:
  name: elasticsearch-sample
spec:
  version: {version}
  image: your/custom/image:tag
  nodeSets:
  - name: default
    count: 1
----

Alternatively, install the plugin when the Pod is created by using an init container:

[source,yaml,subs="attributes"]
----
apiVersion: elasticsearch.k8s.elastic.co/{eck_crd_version}
kind: Elasticsearch
metadata:
  name: elasticsearch-sample
spec:
  version: {version}
  nodeSets:
  - name: default
    count: 1
    podTemplate:
      spec:
        initContainers:
        - name: install-plugins
          command:
          - sh
          - -c
          - |
            bin/elasticsearch-plugin install --batch repository-gcs
----

Assuming you stored this in a file called `elasticsearch.yaml` you can in both cases create the Elasticsearch cluster with:

[source,sh]
----
kubectl apply -f elasticsearch.yaml
----




