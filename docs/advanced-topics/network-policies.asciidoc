:page_id: network-policies
ifdef::env-github[]
****
link:https://www.elastic.co/guide/en/cloud-on-k8s/master/k8s-{page_id}.html[View this document on the Elastic website]
****
endif::[]

:api_server_port: 443
:apm_port: 8200
:dns_port: 53
:ent_port: 3002
:es_http_port: 9200
:es_transport_port: 9300
:kb_port: 5601
:fleet_server_port: 8220
:webhook_port: 9443


[id="{p}-{page_id}"]
= Network policies

link:https://kubernetes.io/docs/concepts/services-networking/network-policies/[Network policies] allow you to isolate pods by restricting incoming and outgoing network connections to a trusted set of sources and destinations. This section describes how to use network policies to isolate the ECK operator and the {stack} applications to a set of namespaces to implement a form of soft multi-tenancy. Soft multi-tenancy is a term used to describe a scenario where a group of trusted users (different teams within an organization, for example) share a single resource such as a Kubernetes cluster. Note that network policies alone are not sufficient for security. You should complement them with strict RBAC policies, resource quotas, node taints, and other available security mechanisms to ensure that tenants cannot access, modify, or disrupt resources belonging to each other.

NOTE: There are several efforts to support multi-tenancy on Kubernetes, including the link:https://github.com/kubernetes-sigs/multi-tenancy[official working group for multi-tenancy] and community extensions such as link:https://loft.sh[loft] and link:https://github.com/kiosk-sh/kiosk[kiosk], that can make configuration and management easier. You might need to employ network policies such the ones described in this section to have fine-grained control over {stack} applications deployed by your tenants.


The following sections assume that the operator is installed in the `elastic-system` namespace with the <<{p}-operator-config,`namespaces` configuration>> set to `team-a,team-b`. Each namespace is expected to be labelled as follows:

[source,sh]
----
kubectl label namespace elastic-system eck.k8s.elastic.co/operator-name=elastic-operator
kubectl label namespace team-a eck.k8s.elastic.co/tenant=team-a
kubectl label namespace team-b eck.k8s.elastic.co/tenant=team-b
----

== Prerequisites

To set up the network policies correctly you must know the operator Pod selector and the Kubernetes API server IP. They may vary depending on your environment and how the operator has been installed.

=== Operator Pod selector

The operator Pod label depends on how the operator has been installed. Check the following table to know which label name is used in the network policies.

[cols="1,1"]
|===
|Installation method |Pod selector

| YAML manifests  a|

`control-plane: elastic-operator`

| Helm Charts a|

`app.kubernetes.io/name: elastic-operator`

|===

NOTE: The examples in this section assume that the ECK operator has been installed using the Helm chart.

=== Kubernetes API server IP

Run `kubectl get endpoints kubernetes -n default` to obtain the API server IP address for your cluster.

NOTE: The following examples assume that the Kubernetes API server IP address is `10.0.0.1`.

[float]
[id="{p}-{page_id}-operator-isolation"]
== Isolating the operator

The minimal set of permissions required are as follows:

[cols="h,1"]
|===
| Egress (outgoing)  a|

* TCP port {api_server_port} of the Kubernetes API server.
* UDP port {dns_port} for DNS lookup.
* TCP port {es_http_port} of {es} nodes on managed namespace.

| Ingress (incoming) a|

* TCP port {webhook_port} for webhook requests from the Kubernetes API server.

|===

[source,yaml,subs="attributes"]
----
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: elastic-operator
  namespace: elastic-system
spec:
  egress:
  - ports:
    - port: {dns_port}
      protocol: UDP
  - ports:
    - port: {api_server_port}
      protocol: TCP
    to:
    - ipBlock:
        cidr: 10.0.0.1/32
  - ports:
    - port: {es_http_port}
      protocol: TCP
    to:
    - namespaceSelector:
        matchExpressions:
        - key: eck.k8s.elastic.co/tenant
          operator: In
          values:
          - team-a
          - team-b
      podSelector:
        matchLabels:
          common.k8s.elastic.co/type: elasticsearch
  ingress:
  - from:
    - ipBlock:
        cidr: 10.0.0.1/32
    ports:
    - port: {webhook_port}
      protocol: TCP
  podSelector:
    matchLabels:
      app.kubernetes.io/name: elastic-operator
----



[float]
[id="{p}-{page_id}-elasticsearch-isolation"]
== Isolating {es}

[cols="h,1"]
|===
| Egress (outgoing)  a|

* TCP port {es_transport_port} to other {es} nodes in the namespace (transport port).
* UDP port {dns_port} for DNS lookup.

| Ingress (incoming) a|

* TCP port {es_http_port} from the operator and other pods in the namespace.

|===


[source,yaml,subs="attributes"]
----
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: eck-elasticsearch
  namespace: team-a
spec:
  egress:
  - ports:
    - port: {es_transport_port}
      protocol: TCP
    to:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
      podSelector:
        matchLabels:
          common.k8s.elastic.co/type: elasticsearch
  - ports:
    - port: {dns_port}
      protocol: UDP
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/operator-name: elastic-operator
      podSelector:
        matchLabels:
          app.kubernetes.io/name: elastic-operator
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
    # [Optional] Allow ingress controller pods from the ingress-nginx namespace.
    #- namespaceSelector:
    #    matchLabels:
    #      name: ingress-nginx
    ports:
    - port: {es_http_port}
      protocol: TCP
  - from:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
      podSelector:
        matchLabels:
          common.k8s.elastic.co/type: elasticsearch
    ports:
    - port: {es_transport_port}
      protocol: TCP
  podSelector:
    matchLabels:
      common.k8s.elastic.co/type: elasticsearch
----



[float]
[id="{p}-{page_id}-kibana-isolation"]
== Isolating {kib}


[cols="h,1"]
|===
| Egress (outgoing)  a|

* TCP port {es_http_port} to {es} nodes in the namespace.
* UDP port {dns_port} for DNS lookup.

| Ingress (incoming) a|

* TCP port {kb_port} from other pods in the namespace.

|===


[source,yaml,subs="attributes"]
----
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: eck-kibana
  namespace: team-a
spec:
  egress:
  - ports:
    - port: {es_http_port}
      protocol: TCP
    to:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
      podSelector:
        matchLabels:
          common.k8s.elastic.co/type: elasticsearch
          # [Optional] Restrict to a single {es} cluster named hulk.
          # elasticsearch.k8s.elastic.co/cluster-name=hulk
  - ports:
    - port: {dns_port}
      protocol: UDP
    # [Optional] If Agent is deployed, this is to allow Kibana to access the Elastic Package Registry (https://epr.elastic.co).
    # - port: 443
    #   protocol: TCP
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
    # [Optional] Allow ingress controller pods from the ingress-nginx namespace.
    #- namespaceSelector:
    #    matchLabels:
    #      name: ingress-nginx
    ports:
    - port: {kb_port}
      protocol: TCP
  podSelector:
    matchLabels:
      common.k8s.elastic.co/type: kibana
----


[float]
[id="{p}-{page_id}-apm-server-isolation"]
== Isolating APM Server


[cols="h,1"]
|===
| Egress (outgoing)  a|

* TCP port {es_http_port} to {es} nodes in the namespace.
* TCP port {kb_port} to {kib} instances in the namespace.
* UDP port {dns_port} for DNS lookup.

| Ingress (incoming) a|

* TCP port {apm_port} from other pods in the namespace.

|===


[source,yaml,subs="attributes"]
----
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: eck-apm-server
  namespace: team-a
spec:
  egress:
  - ports:
    - port: {es_http_port}
      protocol: TCP
    to:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
      podSelector:
        matchLabels:
          common.k8s.elastic.co/type: elasticsearch
  - ports:
    - port: {kb_port}
      protocol: TCP
    to:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
      podSelector:
        matchLabels:
          common.k8s.elastic.co/type: kibana
  - ports:
    - port: {dns_port}
      protocol: UDP
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
    # [Optional] Allow ingress controller pods from the ingress-nginx namespace.
    #- namespaceSelector:
    #    matchLabels:
    #      name: ingress-nginx
    ports:
    - port: {apm_port}
      protocol: TCP
  podSelector:
    matchLabels:
      common.k8s.elastic.co/type: apm-server
----


[float]
[id="{p}-{page_id}-enterprise-search-isolation"]
== Isolating Enterprise Search


[cols="h,1"]
|===
| Egress (outgoing)  a|

* TCP port {es_http_port} to {es} nodes in the namespace.
* UDP port {dns_port} for DNS lookup.

| Ingress (incoming) a|

* TCP port {ent_port} from other pods in the namespace.

|===


[source,yaml,subs="attributes"]
----
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: eck-enterprise-search
  namespace: team-a
spec:
  egress:
  - ports:
    - port: {es_http_port}
      protocol: TCP
    to:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
      podSelector:
        matchLabels:
          common.k8s.elastic.co/type: elasticsearch
  - ports:
    - port: {dns_port}
      protocol: UDP
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
    # [Optional] Allow ingress controller pods from the ingress-nginx namespace.
    #- namespaceSelector:
    #    matchLabels:
    #      name: ingress-nginx
    ports:
    - port: {ent_port}
      protocol: TCP
  podSelector:
    matchLabels:
      common.k8s.elastic.co/type: enterprise-search
----


[float]
[id="{p}-{page_id}-beats-isolation"]
== Isolating {beats}


NOTE: Some {beats} may require additional access rules than what is listed here. For example, {heartbeat} will require a rule to allow access to the endpoint it is monitoring.


[cols="h,1"]
|===
| Egress (outgoing)  a|

* TCP port {es_http_port} to {es} nodes in the namespace.
* TCP port {kb_port} to {kib} instances in the namespace.
* UDP port {dns_port} for DNS lookup.

|===


[source,yaml,subs="attributes"]
----
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: eck-beats
  namespace: team-a
spec:
  egress:
  - ports:
    - port: {es_http_port}
      protocol: TCP
    to:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
      podSelector:
        matchLabels:
          common.k8s.elastic.co/type: elasticsearch
  - ports:
    - port: {kb_port}
      protocol: TCP
    to:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
      podSelector:
        matchLabels:
          common.k8s.elastic.co/type: kibana
  - ports:
    - port: {dns_port}
      protocol: UDP
  podSelector:
    matchLabels:
      common.k8s.elastic.co/type: beat
----

[float]
[id="{p}-{page_id}-agent-isolation"]
== Isolating {agent} and {fleet}


NOTE: Some {agent} policies may require additional access rules other than those listed here.


[cols="h,1"]
|===
| Egress (outgoing)  a|

* TCP port {es_http_port} to {es} nodes in the namespace.
* TCP port {kb_port} to {kib} instances in the namespace.
* TCP port {fleet_server_port} to {fleet} instances in the namespace.
* UDP port {dns_port} for DNS lookup.

|===


[source,yaml,subs="attributes"]
----
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: eck-agent
  namespace: team-a
spec:
  egress:
    - ports:
        - port: {fleet_server_port}
          protocol: TCP
      to:
        - namespaceSelector:
            matchLabels:
              eck.k8s.elastic.co/tenant: team-a
          podSelector:
            matchLabels:
              common.k8s.elastic.co/type: agent
    - ports:
        - port: {kb_port}
          protocol: TCP
      to:
        - namespaceSelector:
            matchLabels:
              eck.k8s.elastic.co/tenant: team-a
          podSelector:
            matchLabels:
              common.k8s.elastic.co/type: kibana
    - ports:
        - port: {es_http_port}
          protocol: TCP
      to:
        - namespaceSelector:
            matchLabels:
              eck.k8s.elastic.co/tenant: team-a
          podSelector:
            matchLabels:
              common.k8s.elastic.co/type: elasticsearch
    - ports:
        - port: {dns_port}
          protocol: UDP
    - ports:
        - port: 443
          protocol: TCP
      to:
        - ipBlock:
            cidr: 10.0.0.1/32
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              eck.k8s.elastic.co/tenant: team-a
      ports:
        - port: {fleet_server_port}
          protocol: TCP
  podSelector:
    matchLabels:
      common.k8s.elastic.co/type: agent
----

[float]
[id="{p}-{page_id}-logstash-isolation"]
== Isolating {ls}


NOTE: {ls} may require additional access rules than those listed here, depending on plugin usage.


[cols="h,1"]
|===
| Egress (outgoing)  a|

* TCP port {es_http_port} to {es} nodes in the namespace.
* UDP port {dns_port} for DNS lookup.

|===


[source,yaml,subs="attributes"]
----
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: eck-logstash
  namespace: team-a
spec:
  egress:
  - ports:
    - port: {es_http_port}
      protocol: TCP
    to:
    - namespaceSelector:
        matchLabels:
          eck.k8s.elastic.co/tenant: team-a
      podSelector:
        matchLabels:
          common.k8s.elastic.co/type: elasticsearch
  - ports:
    - port: {dns_port}
      protocol: UDP
  podSelector:
    matchLabels:
      common.k8s.elastic.co/type: logstash
----
